# Contrastive Multi-Modal Graph Representation Learning for Road-level Operating Mode Distribution Prediction using Open Source Data.
## Brief Introduction
In this study, we propose a contrastive multi-modal graph representation learning framework based on open-source urban data for city-wide operating mode distribution estimation. The framework integrates street view images, satellite images, and road information into unified road embeddings. Pre-trained visual and textual encoders are integrated with graph-based unsupervised learning to capture both cross-modal dependencies and spatial correlations among roads.

## Intuition
Different modalities of data provides complementary information for understanding road characteristics.
![Intuition](Intuition.jpg)

## Modalities and Data Source
- Street view Images (SVIs): Google Map Platform
- Satellite Images: Mapbox
- Tabular data: Open Street Map(OSM)

## Model Architecture
![Model Architecture](Figure1.jpg)
